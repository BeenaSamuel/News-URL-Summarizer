{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "News-summarization-t5-base"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5915.488545,
      "end_time": "2023-11-29T14:41:23.03852",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-29T13:02:47.549975",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U datasets\n",
        "!pip install tensorboard\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "855f7b3b",
        "papermill": {
          "duration": 111.840231,
          "end_time": "2023-11-29T13:04:43.375868",
          "exception": false,
          "start_time": "2023-11-29T13:02:51.535637",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "f17f4135",
        "papermill": {
          "duration": 0.049679,
          "end_time": "2023-11-29T13:04:43.475654",
          "exception": false,
          "start_time": "2023-11-29T13:04:43.425975",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pprint\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "e07f4846",
        "papermill": {
          "duration": 21.856563,
          "end_time": "2023-11-29T13:05:05.383808",
          "exception": false,
          "start_time": "2023-11-29T13:04:43.527245",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp = pprint.PrettyPrinter()"
      ],
      "metadata": {
        "id": "3b5335f4",
        "papermill": {
          "duration": 0.060037,
          "end_time": "2023-11-29T13:05:05.496276",
          "exception": false,
          "start_time": "2023-11-29T13:05:05.436239",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:20.396532Z",
          "iopub.execute_input": "2024-03-14T04:40:20.397099Z",
          "iopub.status.idle": "2024-03-14T04:40:20.40143Z",
          "shell.execute_reply.started": "2024-03-14T04:40:20.397056Z",
          "shell.execute_reply": "2024-03-14T04:40:20.400509Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset"
      ],
      "metadata": {
        "id": "5d05564b",
        "papermill": {
          "duration": 0.049217,
          "end_time": "2023-11-29T13:05:05.596127",
          "exception": false,
          "start_time": "2023-11-29T13:05:05.54691",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('gopalkalpande/bbc-news-summary', split='train')"
      ],
      "metadata": {
        "id": "5fb82bbb",
        "outputId": "f5592f82-dde1-4eba-d8c2-e00118bb8bb0",
        "papermill": {
          "duration": 1.73411,
          "end_time": "2023-11-29T13:05:07.379206",
          "exception": false,
          "start_time": "2023-11-29T13:05:05.645096",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:20.402749Z",
          "iopub.execute_input": "2024-03-14T04:40:20.403015Z",
          "iopub.status.idle": "2024-03-14T04:40:23.085807Z",
          "shell.execute_reply.started": "2024-03-14T04:40:20.402992Z",
          "shell.execute_reply": "2024-03-14T04:40:23.08483Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7f763c2495514a2bb11fcf578dc140d7",
            "77c60b1cb846449b98695601d5ca664a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/2.20k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f763c2495514a2bb11fcf578dc140d7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Downloading data: 100%|██████████| 7.32M/7.32M [00:00<00:00, 16.6MB/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77c60b1cb846449b98695601d5ca664a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = dataset.train_test_split(test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "1b3ef04c",
        "papermill": {
          "duration": 0.069614,
          "end_time": "2023-11-29T13:05:07.498941",
          "exception": false,
          "start_time": "2023-11-29T13:05:07.429327",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:23.087808Z",
          "iopub.execute_input": "2024-03-14T04:40:23.088089Z",
          "iopub.status.idle": "2024-03-14T04:40:23.10399Z",
          "shell.execute_reply.started": "2024-03-14T04:40:23.088064Z",
          "shell.execute_reply": "2024-03-14T04:40:23.103255Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = full_dataset['train']\n",
        "dataset_valid = full_dataset['test']"
      ],
      "metadata": {
        "id": "bacc85a7",
        "papermill": {
          "duration": 0.059713,
          "end_time": "2023-11-29T13:05:07.610298",
          "exception": false,
          "start_time": "2023-11-29T13:05:07.550585",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:23.104998Z",
          "iopub.execute_input": "2024-03-14T04:40:23.105286Z",
          "iopub.status.idle": "2024-03-14T04:40:23.130482Z",
          "shell.execute_reply.started": "2024-03-14T04:40:23.105242Z",
          "shell.execute_reply": "2024-03-14T04:40:23.129722Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_train)\n",
        "print(dataset_valid)"
      ],
      "metadata": {
        "id": "7791ec1d",
        "outputId": "957a1fea-f3ca-474d-8f7a-1b95d1fd5ebf",
        "papermill": {
          "duration": 0.062019,
          "end_time": "2023-11-29T13:05:07.724031",
          "exception": false,
          "start_time": "2023-11-29T13:05:07.662012",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:23.13151Z",
          "iopub.execute_input": "2024-03-14T04:40:23.131821Z",
          "iopub.status.idle": "2024-03-14T04:40:23.141517Z",
          "shell.execute_reply.started": "2024-03-14T04:40:23.131796Z",
          "shell.execute_reply": "2024-03-14T04:40:23.140561Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Dataset({\n    features: ['File_path', 'Articles', 'Summaries'],\n    num_rows: 1779\n})\nDataset({\n    features: ['File_path', 'Articles', 'Summaries'],\n    num_rows: 445\n})\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Analysis"
      ],
      "metadata": {
        "id": "043e5c49",
        "papermill": {
          "duration": 0.050139,
          "end_time": "2023-11-29T13:05:07.826482",
          "exception": false,
          "start_time": "2023-11-29T13:05:07.776343",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_longest_length(dataset):\n",
        "    \"\"\"\n",
        "    Find the longest article and summary in the entire training set.\n",
        "    \"\"\"\n",
        "    max_length = 0\n",
        "    counter_4k = 0\n",
        "    counter_2k = 0\n",
        "    counter_1k = 0\n",
        "    counter_500 = 0\n",
        "    for text in dataset:\n",
        "        corpus = [\n",
        "            word for word in text.split()\n",
        "        ]\n",
        "        if len(corpus) > 4000:\n",
        "            counter_4k += 1\n",
        "        if len(corpus) > 2000:\n",
        "            counter_2k += 1\n",
        "        if len(corpus) > 1000:\n",
        "            counter_1k += 1\n",
        "        if len(corpus) > 500:\n",
        "            counter_500 += 1\n",
        "        if len(corpus) > max_length:\n",
        "            max_length = len(corpus)\n",
        "    return max_length, counter_4k, counter_2k, counter_1k, counter_500\n",
        "\n",
        "longest_article_length, counter_4k, counter_2k, counter_1k, counter_500 = find_longest_length(dataset_train['Articles'])\n",
        "print(f\"Longest article length: {longest_article_length} words\")\n",
        "print(f\"Artciles larger than 4000 words: {counter_4k}\")\n",
        "print(f\"Artciles larger than 2000 words: {counter_2k}\")\n",
        "print(f\"Artciles larger than 1000 words: {counter_1k}\")\n",
        "print(f\"Artciles larger than 500 words: {counter_500}\")\n",
        "longest_summary_length, counter_4k, counter_2k, counter_1k, counter_500 = find_longest_length(dataset_train['Summaries'])\n",
        "print(f\"Longest summary length: {longest_summary_length} words\")\n",
        "print(f\"Summaries larger than 4000 words: {counter_4k}\")\n",
        "print(f\"Summaries larger than 2000 words: {counter_2k}\")\n",
        "print(f\"Summaries larger than 1000 words: {counter_1k}\")\n",
        "print(f\"Summaries larger than 500 words: {counter_500}\")"
      ],
      "metadata": {
        "id": "a79090cd",
        "outputId": "ce5fae09-5d32-4602-aa02-552bbea04032",
        "papermill": {
          "duration": 0.211488,
          "end_time": "2023-11-29T13:05:08.08607",
          "exception": false,
          "start_time": "2023-11-29T13:05:07.874582",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:23.142577Z",
          "iopub.execute_input": "2024-03-14T04:40:23.142854Z",
          "iopub.status.idle": "2024-03-14T04:40:23.294241Z",
          "shell.execute_reply.started": "2024-03-14T04:40:23.142832Z",
          "shell.execute_reply": "2024-03-14T04:40:23.293415Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Longest article length: 4377 words\nArtciles larger than 4000 words: 1\nArtciles larger than 2000 words: 6\nArtciles larger than 1000 words: 17\nArtciles larger than 500 words: 355\nLongest summary length: 2073 words\nSummaries larger than 4000 words: 0\nSummaries larger than 2000 words: 1\nSummaries larger than 1000 words: 6\nSummaries larger than 500 words: 13\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_avg_sentence_length(dataset):\n",
        "    \"\"\"\n",
        "    Find the average sentence in the entire training set.\n",
        "    \"\"\"\n",
        "    sentence_lengths = []\n",
        "    for text in dataset:\n",
        "        corpus = [\n",
        "            word for word in text.split()\n",
        "        ]\n",
        "        sentence_lengths.append(len(corpus))\n",
        "    return sum(sentence_lengths)/len(sentence_lengths)\n",
        "\n",
        "avg_article_length = find_avg_sentence_length(dataset_train['Articles'])\n",
        "print(f\"Average article length: {avg_article_length} words\")\n",
        "avg_summary_length = find_avg_sentence_length(dataset_train['Summaries'])\n",
        "print(f\"Averrage summary length: {avg_summary_length} words\")"
      ],
      "metadata": {
        "id": "7fdf0407",
        "outputId": "e1fc6a15-6895-4a1a-e60a-7b0d7019a3f2",
        "papermill": {
          "duration": 0.210304,
          "end_time": "2023-11-29T13:05:08.349422",
          "exception": false,
          "start_time": "2023-11-29T13:05:08.139118",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:23.295293Z",
          "iopub.execute_input": "2024-03-14T04:40:23.295582Z",
          "iopub.status.idle": "2024-03-14T04:40:23.440342Z",
          "shell.execute_reply.started": "2024-03-14T04:40:23.295542Z",
          "shell.execute_reply": "2024-03-14T04:40:23.439484Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Average article length: 379.849353569421 words\nAverrage summary length: 165.28330522765597 words\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "bf760fe9",
        "papermill": {
          "duration": 0.049171,
          "end_time": "2023-11-29T13:05:08.449381",
          "exception": false,
          "start_time": "2023-11-29T13:05:08.40021",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = 't5-base'\n",
        "BATCH_SIZE = 4\n",
        "NUM_PROCS = 4\n",
        "EPOCHS = 10\n",
        "OUT_DIR = 'results_t5base'\n",
        "MAX_LENGTH = 512 # Maximum context length to consider while preparing dataset."
      ],
      "metadata": {
        "id": "ffcb012e",
        "papermill": {
          "duration": 0.06107,
          "end_time": "2023-11-29T13:05:08.565035",
          "exception": false,
          "start_time": "2023-11-29T13:05:08.503965",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:23.441356Z",
          "iopub.execute_input": "2024-03-14T04:40:23.441647Z",
          "iopub.status.idle": "2024-03-14T04:40:23.445944Z",
          "shell.execute_reply.started": "2024-03-14T04:40:23.441622Z",
          "shell.execute_reply": "2024-03-14T04:40:23.445064Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "8d9becbb",
        "papermill": {
          "duration": 0.052431,
          "end_time": "2023-11-29T13:05:08.670909",
          "exception": false,
          "start_time": "2023-11-29T13:05:08.618478",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "c18dcd2e",
        "papermill": {
          "duration": 0.859621,
          "end_time": "2023-11-29T13:05:09.584289",
          "exception": false,
          "start_time": "2023-11-29T13:05:08.724668",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert text data into model inputs and targets\n",
        "def preprocess_function(examples):\n",
        "    inputs = [f\"summarize: {article}\" for article in examples['Articles']]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    )\n",
        "\n",
        "    # Set up the tokenizer for targets\n",
        "    targets = [summary for summary in examples['Summaries']]\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets,\n",
        "            max_length=MAX_LENGTH,\n",
        "            truncation=True,\n",
        "            padding='max_length'\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the function to the whole dataset\n",
        "tokenized_train = dataset_train.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=NUM_PROCS\n",
        ")\n",
        "tokenized_valid = dataset_valid.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=NUM_PROCS\n",
        ")"
      ],
      "metadata": {
        "id": "b6c89b9b",
        "outputId": "8d4608e3-97d2-48ff-e44d-d01e0d8d0d63",
        "papermill": {
          "duration": 6.217573,
          "end_time": "2023-11-29T13:05:15.856237",
          "exception": false,
          "start_time": "2023-11-29T13:05:09.638664",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:32.382275Z",
          "iopub.execute_input": "2024-03-14T04:40:32.383181Z",
          "iopub.status.idle": "2024-03-14T04:40:37.815152Z",
          "shell.execute_reply.started": "2024-03-14T04:40:32.383145Z",
          "shell.execute_reply": "2024-03-14T04:40:37.814017Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "769fc6eec7974924832b39e3913450a0",
            "c7fb1f7d9a19498692120e5e1490224a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/1779 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "769fc6eec7974924832b39e3913450a0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/445 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7fb1f7d9a19498692120e5e1490224a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "3125a0e4",
        "papermill": {
          "duration": 0.051774,
          "end_time": "2023-11-29T13:05:15.960741",
          "exception": false,
          "start_time": "2023-11-29T13:05:15.908967",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(MODEL)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Total parameters and trainable parameters.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")"
      ],
      "metadata": {
        "id": "0320f5ce",
        "outputId": "dbdfa9f0-2739-48ba-9b6a-9a9b9b017fc8",
        "papermill": {
          "duration": 13.009353,
          "end_time": "2023-11-29T13:05:29.022043",
          "exception": false,
          "start_time": "2023-11-29T13:05:16.01269",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:40:41.102428Z",
          "iopub.execute_input": "2024-03-14T04:40:41.102818Z",
          "iopub.status.idle": "2024-03-14T04:41:05.134846Z",
          "shell.execute_reply.started": "2024-03-14T04:40:41.102786Z",
          "shell.execute_reply": "2024-03-14T04:41:05.133834Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "4085bb9d00f14138a50ec3620ecfb197",
            "ccaae01b56214537a7c1f25d4f73ec5d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4085bb9d00f14138a50ec3620ecfb197"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccaae01b56214537a7c1f25d4f73ec5d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "222,903,552 total parameters.\n222,903,552 training parameters.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROUGE Metric"
      ],
      "metadata": {
        "id": "df04ca1e",
        "papermill": {
          "duration": 0.052939,
          "end_time": "2023-11-29T13:05:29.127796",
          "exception": false,
          "start_time": "2023-11-29T13:05:29.074857",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "691a5a5d",
        "outputId": "995e73f8-058f-4679-e754-d24c9eda3fec",
        "papermill": {
          "duration": 1.02284,
          "end_time": "2023-11-29T13:05:30.20472",
          "exception": false,
          "start_time": "2023-11-29T13:05:29.18188",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:41:09.340806Z",
          "iopub.execute_input": "2024-03-14T04:41:09.341674Z",
          "iopub.status.idle": "2024-03-14T04:41:10.663211Z",
          "shell.execute_reply.started": "2024-03-14T04:41:09.341641Z",
          "shell.execute_reply": "2024-03-14T04:41:10.662302Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "d03cadaa0b724ac79227ddc6976e9a0a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d03cadaa0b724ac79227ddc6976e9a0a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred.predictions[0], eval_pred.label_ids\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True,\n",
        "        rouge_types=[\n",
        "            'rouge1',\n",
        "            'rouge2',\n",
        "            'rougeL'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "26a0a6d4",
        "papermill": {
          "duration": 0.064934,
          "end_time": "2023-11-29T13:05:30.325664",
          "exception": false,
          "start_time": "2023-11-29T13:05:30.26073",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:41:13.102159Z",
          "iopub.execute_input": "2024-03-14T04:41:13.102848Z",
          "iopub.status.idle": "2024-03-14T04:41:13.10995Z",
          "shell.execute_reply.started": "2024-03-14T04:41:13.102816Z",
          "shell.execute_reply": "2024-03-14T04:41:13.109022Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    \"\"\"\n",
        "    Original Trainer may have a memory leak.\n",
        "    This is a workaround to avoid storing too many tensors that are not needed.\n",
        "    \"\"\"\n",
        "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
        "    return pred_ids, labels"
      ],
      "metadata": {
        "id": "e873b864",
        "papermill": {
          "duration": 0.063667,
          "end_time": "2023-11-29T13:05:30.441797",
          "exception": false,
          "start_time": "2023-11-29T13:05:30.37813",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:41:16.679791Z",
          "iopub.execute_input": "2024-03-14T04:41:16.680489Z",
          "iopub.status.idle": "2024-03-14T04:41:16.686679Z",
          "shell.execute_reply.started": "2024-03-14T04:41:16.680436Z",
          "shell.execute_reply": "2024-03-14T04:41:16.685496Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "6eb17cbe",
        "papermill": {
          "duration": 0.053815,
          "end_time": "2023-11-29T13:05:30.549456",
          "exception": false,
          "start_time": "2023-11-29T13:05:30.495641",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=OUT_DIR,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=2,\n",
        "    report_to='tensorboard',\n",
        "    learning_rate=0.0001,\n",
        "    dataloader_num_workers=4\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_valid,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "history = trainer.train()"
      ],
      "metadata": {
        "id": "8858124b",
        "outputId": "9bc5f6b9-fa5c-4e97-8ee9-544fba67bc60",
        "papermill": {
          "duration": 5430.828472,
          "end_time": "2023-11-29T14:36:01.430491",
          "exception": false,
          "start_time": "2023-11-29T13:05:30.602019",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T04:41:20.794365Z",
          "iopub.execute_input": "2024-03-14T04:41:20.794717Z",
          "iopub.status.idle": "2024-03-14T05:55:22.843868Z",
          "shell.execute_reply.started": "2024-03-14T04:41:20.794692Z",
          "shell.execute_reply": "2024-03-14T05:55:22.842872Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2230' max='2230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2230/2230 1:13:56, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.501600</td>\n      <td>0.383298</td>\n      <td>0.898100</td>\n      <td>0.825500</td>\n      <td>0.879300</td>\n      <td>232.741600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.366200</td>\n      <td>0.341916</td>\n      <td>0.904600</td>\n      <td>0.835000</td>\n      <td>0.887400</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.306600</td>\n      <td>0.324870</td>\n      <td>0.908300</td>\n      <td>0.840000</td>\n      <td>0.891100</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.338500</td>\n      <td>0.317775</td>\n      <td>0.910700</td>\n      <td>0.843600</td>\n      <td>0.893900</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.216900</td>\n      <td>0.313120</td>\n      <td>0.912200</td>\n      <td>0.845800</td>\n      <td>0.895500</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.277100</td>\n      <td>0.308870</td>\n      <td>0.913000</td>\n      <td>0.847400</td>\n      <td>0.896200</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.271800</td>\n      <td>0.309013</td>\n      <td>0.914000</td>\n      <td>0.850000</td>\n      <td>0.898000</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.230000</td>\n      <td>0.306556</td>\n      <td>0.914500</td>\n      <td>0.850600</td>\n      <td>0.898300</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.270000</td>\n      <td>0.305663</td>\n      <td>0.915500</td>\n      <td>0.852100</td>\n      <td>0.899700</td>\n      <td>233.087600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.280300</td>\n      <td>0.305169</td>\n      <td>0.915200</td>\n      <td>0.851400</td>\n      <td>0.899200</td>\n      <td>233.089900</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.228000</td>\n      <td>0.306178</td>\n      <td>0.915700</td>\n      <td>0.852100</td>\n      <td>0.899800</td>\n      <td>233.089900</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(OUT_DIR)"
      ],
      "metadata": {
        "id": "87063372",
        "outputId": "8a6178a0-05a8-4f1b-b56e-43fcb2112849",
        "papermill": {
          "duration": 0.068166,
          "end_time": "2023-11-29T14:36:01.581639",
          "exception": false,
          "start_time": "2023-11-29T14:36:01.513473",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T05:55:45.353865Z",
          "iopub.execute_input": "2024-03-14T05:55:45.354255Z",
          "iopub.status.idle": "2024-03-14T05:55:45.365163Z",
          "shell.execute_reply.started": "2024-03-14T05:55:45.354202Z",
          "shell.execute_reply": "2024-03-14T05:55:45.364309Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('results_t5base/tokenizer_config.json',\n 'results_t5base/special_tokens_map.json',\n 'results_t5base/spiece.model',\n 'results_t5base/added_tokens.json')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r {OUT_DIR} {OUT_DIR}"
      ],
      "metadata": {
        "id": "feb20974",
        "outputId": "49531a3e-dee2-419f-8423-d7dcfb319cde",
        "papermill": {
          "duration": 298.691571,
          "end_time": "2023-11-29T14:41:00.325913",
          "exception": false,
          "start_time": "2023-11-29T14:36:01.634342",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T05:55:48.725069Z",
          "iopub.execute_input": "2024-03-14T05:55:48.725787Z",
          "iopub.status.idle": "2024-03-14T06:00:29.482658Z",
          "shell.execute_reply.started": "2024-03-14T05:55:48.725756Z",
          "shell.execute_reply": "2024-03-14T06:00:29.48161Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "  adding: results_t5base/ (stored 0%)\n  adding: results_t5base/tokenizer_config.json (deflated 94%)\n  adding: results_t5base/spiece.model (deflated 48%)\n  adding: results_t5base/events.out.tfevents.1710391281.1231cd64e7b8.34.0 (deflated 69%)\n  adding: results_t5base/special_tokens_map.json (deflated 85%)\n  adding: results_t5base/checkpoint-2007/ (stored 0%)\n  adding: results_t5base/checkpoint-2007/config.json (deflated 63%)\n  adding: results_t5base/checkpoint-2007/rng_state.pth (deflated 25%)\n  adding: results_t5base/checkpoint-2007/optimizer.pt (deflated 8%)\n  adding: results_t5base/checkpoint-2007/trainer_state.json (deflated 82%)\n  adding: results_t5base/checkpoint-2007/model.safetensors (deflated 8%)\n  adding: results_t5base/checkpoint-2007/generation_config.json (deflated 27%)\n  adding: results_t5base/checkpoint-2007/scheduler.pt (deflated 55%)\n  adding: results_t5base/checkpoint-2007/training_args.bin (deflated 51%)\n  adding: results_t5base/checkpoint-2230/ (stored 0%)\n  adding: results_t5base/checkpoint-2230/config.json (deflated 63%)\n  adding: results_t5base/checkpoint-2230/rng_state.pth (deflated 25%)\n  adding: results_t5base/checkpoint-2230/optimizer.pt (deflated 8%)\n  adding: results_t5base/checkpoint-2230/trainer_state.json (deflated 82%)\n  adding: results_t5base/checkpoint-2230/model.safetensors (deflated 8%)\n  adding: results_t5base/checkpoint-2230/generation_config.json (deflated 27%)\n  adding: results_t5base/checkpoint-2230/scheduler.pt (deflated 56%)\n  adding: results_t5base/checkpoint-2230/training_args.bin (deflated 51%)\n  adding: results_t5base/added_tokens.json (deflated 83%)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "6140f3a3",
        "papermill": {
          "duration": 0.051548,
          "end_time": "2023-11-29T14:41:00.429597",
          "exception": false,
          "start_time": "2023-11-29T14:41:00.378049",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data.\n",
        "!wget \"https://www.dropbox.com/scl/fi/561r8pfhem4lu70hf438q/inference_data.zip?rlkey=aedt2saqmmp3a67qc4o34k04y&dl=1\" -O inference_data.zip"
      ],
      "metadata": {
        "id": "f4cad668",
        "papermill": {
          "duration": 3.283808,
          "end_time": "2023-11-29T14:41:03.766466",
          "exception": false,
          "start_time": "2023-11-29T14:41:00.482658",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-13T17:14:47.023963Z",
          "iopub.execute_input": "2024-03-13T17:14:47.024903Z",
          "iopub.status.idle": "2024-03-13T17:14:49.484822Z",
          "shell.execute_reply.started": "2024-03-13T17:14:47.024863Z",
          "shell.execute_reply": "2024-03-13T17:14:49.483639Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip inference_data.zip"
      ],
      "metadata": {
        "id": "c253201c",
        "papermill": {
          "duration": 1.132326,
          "end_time": "2023-11-29T14:41:04.950058",
          "exception": false,
          "start_time": "2023-11-29T14:41:03.817732",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-13T17:14:49.486336Z",
          "iopub.execute_input": "2024-03-13T17:14:49.486636Z",
          "iopub.status.idle": "2024-03-13T17:14:50.500897Z",
          "shell.execute_reply.started": "2024-03-13T17:14:49.48661Z",
          "shell.execute_reply": "2024-03-13T17:14:50.499901Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n"
      ],
      "metadata": {
        "id": "6ce574fb",
        "papermill": {
          "duration": 0.061285,
          "end_time": "2023-11-29T14:41:05.064333",
          "exception": false,
          "start_time": "2023-11-29T14:41:05.003048",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T06:06:03.12073Z",
          "iopub.execute_input": "2024-03-14T06:06:03.121392Z",
          "iopub.status.idle": "2024-03-14T06:06:03.125706Z",
          "shell.execute_reply.started": "2024-03-14T06:06:03.121357Z",
          "shell.execute_reply": "2024-03-14T06:06:03.124718Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f\"{OUT_DIR}/checkpoint-2230\"  # the path where you saved your model\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained(OUT_DIR)"
      ],
      "metadata": {
        "id": "7f84e37e",
        "outputId": "6b015f6b-809c-4553-ce4e-0082b2185761",
        "papermill": {
          "duration": 2.99533,
          "end_time": "2023-11-29T14:41:08.113592",
          "exception": false,
          "start_time": "2023-11-29T14:41:05.118262",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-03-14T06:08:50.007919Z",
          "iopub.execute_input": "2024-03-14T06:08:50.008549Z",
          "iopub.status.idle": "2024-03-14T06:08:51.084085Z",
          "shell.execute_reply.started": "2024-03-14T06:08:50.008516Z",
          "shell.execute_reply": "2024-03-14T06:08:51.083005Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install huggingface_hub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-13T17:32:22.426373Z",
          "iopub.execute_input": "2024-03-13T17:32:22.426757Z",
          "iopub.status.idle": "2024-03-13T17:32:34.776233Z",
          "shell.execute_reply.started": "2024-03-13T17:32:22.426726Z",
          "shell.execute_reply": "2024-03-13T17:32:34.775101Z"
        },
        "trusted": true,
        "id": "eS89gS3FdRD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:09:26.560112Z",
          "iopub.execute_input": "2024-03-14T06:09:26.560836Z",
          "iopub.status.idle": "2024-03-14T06:09:26.590042Z",
          "shell.execute_reply.started": "2024-03-14T06:09:26.560801Z",
          "shell.execute_reply": "2024-03-14T06:09:26.58918Z"
        },
        "trusted": true,
        "id": "enZ04_SFdRD9",
        "outputId": "2cb1448a-6928-4bc8-e845-ff52a293f56a",
        "colab": {
          "referenced_widgets": [
            "54918d2fb0014705a39267ef052dbfb6"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54918d2fb0014705a39267ef052dbfb6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"bbc-news-summarizer\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:10:06.506049Z",
          "iopub.execute_input": "2024-03-14T06:10:06.506698Z",
          "iopub.status.idle": "2024-03-14T06:10:39.841492Z",
          "shell.execute_reply.started": "2024-03-14T06:10:06.506662Z",
          "shell.execute_reply": "2024-03-14T06:10:39.840516Z"
        },
        "trusted": true,
        "id": "lqYN1TZmdRD-",
        "outputId": "cec68527-af23-4616-de91-f81accd715da",
        "colab": {
          "referenced_widgets": [
            "22c4835240a1436aa9ced4236d8d76d7"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22c4835240a1436aa9ced4236d8d76d7"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/BeenaSamuel/bbc-news-summarizer/commit/be8f29a61e935055bd84d8b52a7e0a0db70253ef', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='be8f29a61e935055bd84d8b52a7e0a0db70253ef', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\"bbc-news-summarizer\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:11:14.268548Z",
          "iopub.execute_input": "2024-03-14T06:11:14.269366Z",
          "iopub.status.idle": "2024-03-14T06:11:15.810049Z",
          "shell.execute_reply.started": "2024-03-14T06:11:14.26933Z",
          "shell.execute_reply": "2024-03-14T06:11:15.809013Z"
        },
        "trusted": true,
        "id": "GWTZdip6dRD-",
        "outputId": "e0d87349-cffc-4c6f-88a1-6dd4e257f7de",
        "colab": {
          "referenced_widgets": [
            "0264435001d7453899643669359793dc",
            "d51615fa395a4f72b365a6bf4275a088"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0264435001d7453899643669359793dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d51615fa395a4f72b365a6bf4275a088"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/BeenaSamuel/bbc-news-summarizer/commit/f85298526ffa0da7244e3b3a35697ee803db5848', commit_message='Upload tokenizer', commit_description='', oid='f85298526ffa0da7244e3b3a35697ee803db5848', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir=\"bbc-news-summarizer\", push_to_hub=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:13:09.792566Z",
          "iopub.execute_input": "2024-03-14T06:13:09.793514Z",
          "iopub.status.idle": "2024-03-14T06:13:09.801511Z",
          "shell.execute_reply.started": "2024-03-14T06:13:09.79348Z",
          "shell.execute_reply": "2024-03-14T06:13:09.800696Z"
        },
        "trusted": true,
        "id": "Hg5b1T8fdRD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:13:22.277215Z",
          "iopub.execute_input": "2024-03-14T06:13:22.278058Z",
          "iopub.status.idle": "2024-03-14T06:13:22.285072Z",
          "shell.execute_reply.started": "2024-03-14T06:13:22.278025Z",
          "shell.execute_reply": "2024-03-14T06:13:22.284164Z"
        },
        "trusted": true,
        "id": "84RojtuSdRD-",
        "outputId": "7f9067d7-f7f3-4d0f-cbbd-3408f91c5662"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=2,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=False,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=None,\nevaluation_strategy=no,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=5e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=bbc-news-summarizer/runs/Mar14_06-13-09_1231cd64e7b8,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noutput_dir=bbc-news-summarizer,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=8,\nper_device_train_batch_size=8,\nprediction_loss_only=False,\npush_to_hub=True,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nresume_from_checkpoint=None,\nrun_name=bbc-news-summarizer,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=steps,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:13:50.114636Z",
          "iopub.execute_input": "2024-03-14T06:13:50.115737Z",
          "iopub.status.idle": "2024-03-14T06:14:17.816527Z",
          "shell.execute_reply.started": "2024-03-14T06:13:50.115689Z",
          "shell.execute_reply": "2024-03-14T06:14:17.815566Z"
        },
        "trusted": true,
        "id": "2NiTrCK0dRD-",
        "outputId": "77008465-1096-4982-a02e-3dec019d3d4f",
        "colab": {
          "referenced_widgets": [
            "43702c72ebff4372a6a81e207209e838",
            "aa4d35917ff94a5185741c37acaa7bc2",
            "e0c1c26c00cf414f9a66a37bbd97ba3d",
            "71746560c6014588930a575adcde6730",
            "16c281c9e5e14897805529ff20ccb1d8"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43702c72ebff4372a6a81e207209e838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa4d35917ff94a5185741c37acaa7bc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0c1c26c00cf414f9a66a37bbd97ba3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "events.out.tfevents.1710391281.1231cd64e7b8.34.0:   0%|          | 0.00/57.9k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71746560c6014588930a575adcde6730"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16c281c9e5e14897805529ff20ccb1d8"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/BeenaSamuel/results_t5base/commit/ee45355857bcde2453c4e3f8d3a204099e296663', commit_message='End of training', commit_description='', oid='ee45355857bcde2453c4e3f8d3a204099e296663', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hxzE_ZsdRD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(r'/kaggle/working/')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:00:29.484603Z",
          "iopub.execute_input": "2024-03-14T06:00:29.484929Z",
          "iopub.status.idle": "2024-03-14T06:00:29.48997Z",
          "shell.execute_reply.started": "2024-03-14T06:00:29.484897Z",
          "shell.execute_reply": "2024-03-14T06:00:29.489113Z"
        },
        "trusted": true,
        "id": "DWoTsd-hdRD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "\n",
        "FileLink(r'results_t5base.zip')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:00:35.730933Z",
          "iopub.execute_input": "2024-03-14T06:00:35.731319Z",
          "iopub.status.idle": "2024-03-14T06:00:35.737749Z",
          "shell.execute_reply.started": "2024-03-14T06:00:35.731288Z",
          "shell.execute_reply": "2024-03-14T06:00:35.736796Z"
        },
        "trusted": true,
        "id": "P22f1x-2dRD-",
        "outputId": "8f23783d-cd1c-4f46-c27f-50764aa38b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "/kaggle/working/results_t5base.zip",
            "text/html": "<a href='results_t5base.zip' target='_blank'>results_t5base.zip</a><br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel, AutoConfig"
      ],
      "metadata": {
        "trusted": true,
        "id": "tpS6H8zQdRD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"BeenaSamuel/bbc-news-summarizer\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:21:19.001193Z",
          "iopub.execute_input": "2024-03-14T06:21:19.001565Z",
          "iopub.status.idle": "2024-03-14T06:21:19.00565Z",
          "shell.execute_reply.started": "2024-03-14T06:21:19.001536Z",
          "shell.execute_reply": "2024-03-14T06:21:19.004754Z"
        },
        "trusted": true,
        "id": "8ii5chFFdRD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_load = AutoConfig.from_pretrained(model_name)\n",
        "config_load"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:21:23.751875Z",
          "iopub.execute_input": "2024-03-14T06:21:23.75232Z",
          "iopub.status.idle": "2024-03-14T06:21:23.922148Z",
          "shell.execute_reply.started": "2024-03-14T06:21:23.752248Z",
          "shell.execute_reply": "2024-03-14T06:21:23.921296Z"
        },
        "trusted": true,
        "id": "4HWeQgeodREB",
        "outputId": "b303722d-d770-41d9-fd2f-21826532986f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "T5Config {\n  \"_name_or_path\": \"BeenaSamuel/bbc-news-summarizer\",\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"classifier_dropout\": 0.0,\n  \"d_ff\": 3072,\n  \"d_kv\": 64,\n  \"d_model\": 768,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"relu\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"relu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": false,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"t5\",\n  \"n_positions\": 512,\n  \"num_decoder_layers\": 12,\n  \"num_heads\": 12,\n  \"num_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 200,\n      \"min_length\": 30,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4,\n      \"prefix\": \"summarize: \"\n    },\n    \"translation_en_to_de\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to German: \"\n    },\n    \"translation_en_to_fr\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to French: \"\n    },\n    \"translation_en_to_ro\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to Romanian: \"\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.38.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32128\n}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = TFAutoModel.from_pretrained(model_name)\n",
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:21:30.402855Z",
          "iopub.execute_input": "2024-03-14T06:21:30.403218Z",
          "iopub.status.idle": "2024-03-14T06:21:32.921787Z",
          "shell.execute_reply.started": "2024-03-14T06:21:30.403191Z",
          "shell.execute_reply": "2024-03-14T06:21:32.920908Z"
        },
        "trusted": true,
        "id": "STeKJmFQdREB",
        "outputId": "486ebe8d-187d-47bc-ada1-d22a820c5c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "All PyTorch model weights were used when initializing TFT5Model.\n\nAll the weights of TFT5Model were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-14T06:21:41.49535Z",
          "iopub.execute_input": "2024-03-14T06:21:41.496183Z",
          "iopub.status.idle": "2024-03-14T06:21:41.552541Z",
          "shell.execute_reply.started": "2024-03-14T06:21:41.496151Z",
          "shell.execute_reply": "2024-03-14T06:21:41.551713Z"
        },
        "trusted": true,
        "id": "XLzDP4VrdREB",
        "outputId": "64e79463-d7e0-4227-c36b-5535d6ba64e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"tft5_model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n shared (Embedding)          multiple                  24674304  \n                                                                 \n encoder (TFT5MainLayer)     multiple                  109628544 \n                                                                 \n decoder (TFT5MainLayer)     multiple                  137949312 \n                                                                 \n=================================================================\nTotal params: 222903552 (850.31 MB)\nTrainable params: 222903552 (850.31 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}